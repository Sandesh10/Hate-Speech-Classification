{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment(file):\n",
    "    with open(os.path.join(mydir,file+\".txt\"), 'r', encoding='utf8') as f:\n",
    "        return f.read().lower()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = 'C:\\\\Users\\\\Sandesh\\\\Desktop\\\\hate-speech-dataset\\\\all_files'\n",
    "df =pd.read_csv(\"C:/Users/Sandesh/Desktop/hate-speech-dataset/annotations_metadata.csv\")\n",
    "df['text'] = df['file_id'].apply(lambda x:get_comment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'noHate': 1, 'hate':2, 'relation':3,'idk/skip':4 }\n",
    "df['new_label'] = df['label'].apply(lambda s: mapping.get(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>new_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12834217_1</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>as of march 13th , 2014 , the booklet had been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12834217_2</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>in order to help increase the booklets downloa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12834217_3</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>( simply copy and paste the following text int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12834217_4</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>hate</td>\n",
       "      <td>click below for a free download of a colorfull...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12834217_5</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>click on the `` download ( 7.42 mb ) '' green ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id  user_id  subforum_id  num_contexts   label  \\\n",
       "0  12834217_1   572066         1346             0  noHate   \n",
       "1  12834217_2   572066         1346             0  noHate   \n",
       "2  12834217_3   572066         1346             0  noHate   \n",
       "3  12834217_4   572066         1346             0    hate   \n",
       "4  12834217_5   572066         1346             0  noHate   \n",
       "\n",
       "                                                text  new_label  \n",
       "0  as of march 13th , 2014 , the booklet had been...          1  \n",
       "1  in order to help increase the booklets downloa...          1  \n",
       "2  ( simply copy and paste the following text int...          1  \n",
       "3  click below for a free download of a colorfull...          2  \n",
       "4  click on the `` download ( 7.42 mb ) '' green ...          1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Labels')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# use pathlib to load path\n",
    "data_root = pathlib.Path('./')\n",
    "df = pd.read_csv(data_root/'raw.csv', error_bad_lines=False)\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x=df.label.unique(),y=df.label.value_counts());\n",
    "ax.set(xlabel='Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the vocab of all unique words in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████████████████████████████████████████████████████████| 10944/10944 [00:00<00:00, 195557.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10944/10944 [00:06<00:00, 1651.39it/s]\n",
      "Progress: 100%|████████████████████████████████████████████████████████████████| 10944/10944 [00:05<00:00, 2179.34it/s]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████| 10944/10944 [00:00<00:00, 238166.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Tweet Length')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the vocab of all unique words in lowercase\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "# load spacy tokenizer\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "# df.progress_apply is tqdm method for pandas. It shows progress bar for apply function\n",
    "# remove the leading and trailing spaces\n",
    "df['text'] = df.text.progress_apply(lambda x: x.strip())\n",
    "\n",
    "# build vocabulary and corresponding counts\n",
    "words = Counter()\n",
    "for sent in tqdm(df.text.values):\n",
    "    words.update(w.text.lower() for w in nlp(sent))\n",
    "   \n",
    "# sort with most frequently occuring words first\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "# add <pad> and <unk> token to vocab which will be used later\n",
    "words = ['_PAD','_UNK'] + words\n",
    "\n",
    "# create word to index dictionary and reverse\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "\n",
    "def indexer(s): \n",
    "    return [word2idx[w.text.lower()] for w in nlp(s)]\n",
    "\n",
    "# tokenize the tweets and calculate lengths\n",
    "df['textidx'] = df.text.progress_apply(indexer)\n",
    "df['lengths'] = df.textidx.progress_apply(len)\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = sns.distplot(df.lengths.values,kde=False);\n",
    "ax.set(xlabel='Tweet Length', ylabel='Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>new_label</th>\n",
       "      <th>textidx</th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12834217_1</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>as of march 13th , 2014 , the booklet had been...</td>\n",
       "      <td>1</td>\n",
       "      <td>[35, 9, 520, 3992, 4, 1452, 4, 3, 1838, 94, 88...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12834217_2</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>in order to help increase the booklets downloa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 703, 6, 321, 3994, 3, 5088, 2456, 4, 12, ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12834217_3</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>( simply copy and paste the following text int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[56, 806, 1292, 7, 3288, 3, 1069, 965, 130, 50...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12834217_4</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>hate</td>\n",
       "      <td>click below for a free download of a colorfull...</td>\n",
       "      <td>2</td>\n",
       "      <td>[632, 832, 16, 8, 222, 807, 9, 8, 5089, 5090, ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12834217_5</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>click on the `` download ( 7.42 mb ) '' green ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[632, 19, 3, 26, 26, 807, 56, 7377, 3997, 54, ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id  user_id  subforum_id  num_contexts   label  \\\n",
       "0  12834217_1   572066         1346             0  noHate   \n",
       "1  12834217_2   572066         1346             0  noHate   \n",
       "2  12834217_3   572066         1346             0  noHate   \n",
       "3  12834217_4   572066         1346             0    hate   \n",
       "4  12834217_5   572066         1346             0  noHate   \n",
       "\n",
       "                                                text  new_label  \\\n",
       "0  as of march 13th , 2014 , the booklet had been...          1   \n",
       "1  in order to help increase the booklets downloa...          1   \n",
       "2  ( simply copy and paste the following text int...          1   \n",
       "3  click below for a free download of a colorfull...          2   \n",
       "4  click on the `` download ( 7.42 mb ) '' green ...          1   \n",
       "\n",
       "                                             textidx  lengths  \n",
       "0  [35, 9, 520, 3992, 4, 1452, 4, 3, 1838, 94, 88...       18  \n",
       "1  [10, 703, 6, 321, 3994, 3, 5088, 2456, 4, 12, ...       36  \n",
       "2  [56, 806, 1292, 7, 3288, 3, 1069, 965, 130, 50...       16  \n",
       "3  [632, 832, 16, 8, 222, 807, 9, 8, 5089, 5090, ...       26  \n",
       "4  [632, 19, 3, 26, 26, 807, 56, 7377, 3997, 54, ...       15  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████████████████████████████████████████████████████████| 10944/10944 [00:00<00:00, 214728.27it/s]\n",
      "Progress: 100%|████████████████████████████████████████████████████████████████| 10944/10944 [00:05<00:00, 2171.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0    [35, 9, 520, 3992, 4, 1452, 4, 3, 1838, 94, 88...\n",
      "1    [10, 703, 6, 321, 3994, 3, 5088, 2456, 4, 12, ...\n",
      "2    [56, 806, 1292, 7, 3288, 3, 1069, 965, 130, 50...\n",
      "3    [632, 832, 16, 8, 222, 807, 9, 8, 5089, 5090, ...\n",
      "Name: sentimentidx, dtype: object, 0    1\n",
      "1    1\n",
      "2    1\n",
      "3    2\n",
      "Name: new_label, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# subclass the custom dataset class with torch.utils.data.Dataset\n",
    "# implement __len__ and __getitem__ function\n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df_path):\n",
    "        self.df = pd.read_csv(df_path, error_bad_lines=False)\n",
    "        self.df['SentimentText'] = self.df.text.progress_apply(lambda x: x.strip())\n",
    "        self.df['sentimentidx'] = self.df.text.progress_apply(indexer)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.sentimentidx[idx]\n",
    "        y = self.df.new_label[idx]\n",
    "        return X,y\n",
    "      \n",
    "# create instance of custom dataset\n",
    "ds = VectorizeData('raw.csv')\n",
    "# get first 4 samples\n",
    "print(ds[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>new_label</th>\n",
       "      <th>textidx</th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12834217_1</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>as of march 13th , 2014 , the booklet had been...</td>\n",
       "      <td>1</td>\n",
       "      <td>[35, 9, 520, 3992, 4, 1452, 4, 3, 1838, 94, 88...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12834217_2</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>in order to help increase the booklets downloa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 703, 6, 321, 3994, 3, 5088, 2456, 4, 12, ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12834217_3</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>( simply copy and paste the following text int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[56, 806, 1292, 7, 3288, 3, 1069, 965, 130, 50...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12834217_4</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>hate</td>\n",
       "      <td>click below for a free download of a colorfull...</td>\n",
       "      <td>2</td>\n",
       "      <td>[632, 832, 16, 8, 222, 807, 9, 8, 5089, 5090, ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12834217_5</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>click on the `` download ( 7.42 mb ) '' green ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[632, 19, 3, 26, 26, 807, 56, 7377, 3997, 54, ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id  user_id  subforum_id  num_contexts   label  \\\n",
       "0  12834217_1   572066         1346             0  noHate   \n",
       "1  12834217_2   572066         1346             0  noHate   \n",
       "2  12834217_3   572066         1346             0  noHate   \n",
       "3  12834217_4   572066         1346             0    hate   \n",
       "4  12834217_5   572066         1346             0  noHate   \n",
       "\n",
       "                                                text  new_label  \\\n",
       "0  as of march 13th , 2014 , the booklet had been...          1   \n",
       "1  in order to help increase the booklets downloa...          1   \n",
       "2  ( simply copy and paste the following text int...          1   \n",
       "3  click below for a free download of a colorfull...          2   \n",
       "4  click on the `` download ( 7.42 mb ) '' green ...          1   \n",
       "\n",
       "                                             textidx  lengths  \n",
       "0  [35, 9, 520, 3992, 4, 1452, 4, 3, 1838, 94, 88...       18  \n",
       "1  [10, 703, 6, 321, 3994, 3, 5088, 2456, 4, 12, ...       36  \n",
       "2  [56, 806, 1292, 7, 3288, 3, 1069, 965, 130, 50...       16  \n",
       "3  [632, 832, 16, 8, 222, 807, 9, 8, 5089, 5090, ...       26  \n",
       "4  [632, 19, 3, 26, 26, 807, 56, 7377, 3997, 54, ...       15  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples 3648\n",
      "Length of smallest tweet 16\n",
      "<class 'list'>\n",
      "[tensor([35, 10, 56]), tensor([  9, 703, 806]), tensor([ 520,    6, 1292]), tensor([3992,  321,    7]), tensor([   4, 3994, 3288]), tensor([1452,    3,    3]), tensor([   4, 5088, 1069]), tensor([   3, 2456,  965]), tensor([1838,    4,  130]), tensor([94, 12, 50]), tensor([88, 61, 67]), tensor([2455,   32,  460]), tensor([ 129,  142, 2017]), tensor([5087,   39, 3286]), tensor([210,  31,   2]), tensor([   7, 3995,   54])]\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset=ds, batch_size=3) \n",
    "print('Total samples', len(dl))\n",
    "# Total batches 526204\n",
    "\n",
    "it = iter(dl)\n",
    "xs,ys = next(it)\n",
    "print('Length of smallest tweet', len(xs))\n",
    "print(type(xs))\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress:   0%|                                                                              | 0/10944 [00:00<?, ?it/s]\n",
      "Progress:   2%|█▌                                                                | 259/10944 [00:00<00:04, 2578.20it/s]\n",
      "Progress:   5%|███▎                                                              | 554/10944 [00:00<00:03, 2679.34it/s]\n",
      "Progress:   8%|█████                                                             | 847/10944 [00:00<00:03, 2742.71it/s]\n",
      "Progress:  11%|██████▊                                                          | 1152/10944 [00:00<00:03, 2820.82it/s]\n",
      "Progress:  13%|████████▌                                                        | 1443/10944 [00:00<00:03, 2839.35it/s]\n",
      "Progress:  16%|██████████▎                                                      | 1732/10944 [00:00<00:03, 2850.58it/s]\n",
      "Progress:  18%|███████████▉                                                     | 2003/10944 [00:00<00:03, 2784.75it/s]\n",
      "Progress:  21%|█████████████▍                                                   | 2262/10944 [00:00<00:03, 2586.71it/s]\n",
      "Progress:  23%|██████████████▉                                                  | 2510/10944 [00:00<00:03, 2292.32it/s]\n",
      "Progress:  26%|████████████████▋                                                | 2810/10944 [00:01<00:03, 2461.21it/s]\n",
      "Progress:  28%|██████████████████▍                                              | 3098/10944 [00:01<00:03, 2567.03it/s]\n",
      "Progress:  31%|████████████████████                                             | 3388/10944 [00:01<00:02, 2651.77it/s]\n",
      "Progress:  34%|█████████████████████▊                                           | 3676/10944 [00:01<00:02, 2709.15it/s]\n",
      "Progress:  36%|███████████████████████▌                                         | 3963/10944 [00:01<00:02, 2748.01it/s]\n",
      "Progress:  39%|█████████████████████████▎                                       | 4271/10944 [00:01<00:02, 2832.47it/s]\n",
      "Progress:  42%|███████████████████████████                                      | 4557/10944 [00:01<00:02, 2525.32it/s]\n",
      "Progress:  44%|████████████████████████████▌                                    | 4817/10944 [00:01<00:02, 2297.94it/s]\n",
      "Progress:  46%|██████████████████████████████                                   | 5056/10944 [00:01<00:02, 2246.53it/s]\n",
      "Progress:  48%|███████████████████████████████▍                                 | 5288/10944 [00:02<00:02, 2216.48it/s]\n",
      "Progress:  50%|████████████████████████████████▊                                | 5515/10944 [00:02<00:02, 2007.71it/s]\n",
      "Progress:  52%|█████████████████████████████████▉                               | 5723/10944 [00:02<00:02, 1906.56it/s]\n",
      "Progress:  54%|███████████████████████████████████▏                             | 5920/10944 [00:02<00:02, 1844.43it/s]\n",
      "Progress:  56%|████████████████████████████████████▎                            | 6110/10944 [00:02<00:02, 1743.29it/s]\n",
      "Progress:  57%|█████████████████████████████████████▎                           | 6289/10944 [00:02<00:02, 1716.95it/s]\n",
      "Progress:  59%|██████████████████████████████████████▍                          | 6464/10944 [00:02<00:02, 1699.32it/s]\n",
      "Progress:  61%|███████████████████████████████████████▍                         | 6637/10944 [00:02<00:02, 1693.67it/s]\n",
      "Progress:  62%|████████████████████████████████████████▌                        | 6824/10944 [00:02<00:02, 1738.41it/s]\n",
      "Progress:  64%|█████████████████████████████████████████▋                       | 7012/10944 [00:03<00:02, 1773.88it/s]\n",
      "Progress:  66%|██████████████████████████████████████████▋                      | 7194/10944 [00:03<00:02, 1782.55it/s]\n",
      "Progress:  68%|███████████████████████████████████████████▉                     | 7394/10944 [00:03<00:01, 1837.85it/s]\n",
      "Progress:  69%|█████████████████████████████████████████████                    | 7594/10944 [00:03<00:01, 1878.68it/s]\n",
      "Progress:  71%|██████████████████████████████████████████████▎                  | 7795/10944 [00:03<00:01, 1911.11it/s]\n",
      "Progress:  73%|███████████████████████████████████████████████▍                 | 7987/10944 [00:03<00:01, 1869.44it/s]\n",
      "Progress:  75%|████████████████████████████████████████████████▌                | 8175/10944 [00:03<00:01, 1867.36it/s]\n",
      "Progress:  76%|█████████████████████████████████████████████████▋               | 8369/10944 [00:03<00:01, 1883.41it/s]\n",
      "Progress:  78%|██████████████████████████████████████████████████▊              | 8558/10944 [00:03<00:01, 1877.67it/s]\n",
      "Progress:  80%|███████████████████████████████████████████████████▉             | 8747/10944 [00:04<00:01, 1859.50it/s]\n",
      "Progress:  82%|█████████████████████████████████████████████████████            | 8939/10944 [00:04<00:01, 1872.09it/s]\n",
      "Progress:  83%|██████████████████████████████████████████████████████▏          | 9127/10944 [00:04<00:00, 1841.76it/s]\n",
      "Progress:  85%|███████████████████████████████████████████████████████▎         | 9312/10944 [00:04<00:00, 1785.85it/s]\n",
      "Progress:  87%|████████████████████████████████████████████████████████▍        | 9505/10944 [00:04<00:00, 1821.91it/s]\n",
      "Progress:  89%|█████████████████████████████████████████████████████████▌       | 9688/10944 [00:04<00:00, 1797.82it/s]\n",
      "Progress:  90%|██████████████████████████████████████████████████████████▌      | 9869/10944 [00:04<00:00, 1788.38it/s]\n",
      "Progress:  92%|██████████████████████████████████████████████████████████▊     | 10049/10944 [00:04<00:00, 1750.39it/s]\n",
      "Progress:  94%|███████████████████████████████████████████████████████████▉    | 10243/10944 [00:04<00:00, 1798.55it/s]\n",
      "Progress:  96%|█████████████████████████████████████████████████████████████▏  | 10458/10944 [00:04<00:00, 1886.62it/s]\n",
      "Progress:  97%|██████████████████████████████████████████████████████████████▎ | 10649/10944 [00:05<00:00, 1828.70it/s]\n",
      "Progress: 100%|████████████████████████████████████████████████████████████████| 10944/10944 [00:05<00:00, 2098.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating lengths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████| 10944/10944 [00:00<00:00, 165918.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress:   0%|                                                                              | 0/10944 [00:00<?, ?it/s]\n",
      "Progress: 100%|███████████████████████████████████████████████████████████████| 10944/10944 [00:00<00:00, 59192.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0        [35, 9, 520, 3992, 4, 1452, 4, 3, 1838, 94]\n",
      "1      [10, 703, 6, 321, 3994, 3, 5088, 2456, 4, 12]\n",
      "2    [56, 806, 1292, 7, 3288, 3, 1069, 965, 130, 50]\n",
      "3      [632, 832, 16, 8, 222, 807, 9, 8, 5089, 5090]\n",
      "4      [632, 19, 3, 26, 26, 807, 56, 7377, 3997, 54]\n",
      "Name: sentimentpadded, dtype: object, 0    noHate\n",
      "1    noHate\n",
      "2    noHate\n",
      "3      hate\n",
      "4    noHate\n",
      "Name: label, dtype: object, 0    10\n",
      "1    10\n",
      "2    10\n",
      "3    10\n",
      "4    10\n",
      "Name: lengths, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df_path, maxlen=10):\n",
    "        self.maxlen = maxlen\n",
    "        self.df = pd.read_csv(df_path, error_bad_lines=False)\n",
    "        self.df['text'] = self.df.text.apply(lambda x: x.strip())\n",
    "        print('Indexing...')\n",
    "        self.df['sentimentidx'] = self.df.text.progress_apply(indexer)\n",
    "        print('Calculating lengths')\n",
    "        self.df['lengths'] = self.df.sentimentidx.progress_apply(lambda x: self.maxlen if len(x) > self.maxlen else len(x))\n",
    "        print('Padding')\n",
    "        self.df['sentimentpadded'] = self.df.sentimentidx.progress_apply(self.pad_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.sentimentpadded[idx]\n",
    "        lens = self.df.lengths[idx]\n",
    "        y = self.df.label[idx]\n",
    "        return X,y,lens\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
    "        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded\n",
    "      \n",
    "ds = VectorizeData(data_root/'raw.csv')\n",
    "print(ds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3648\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset=ds, batch_size=3)\n",
    "print(len(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[  35,    9,  520, 3992,    4, 1452,    4,    3, 1838,   94],\n",
      "        [  10,  703,    6,  321, 3994,    3, 5088, 2456,    4,   12],\n",
      "        [  56,  806, 1292,    7, 3288,    3, 1069,  965,  130,   50]])\n"
     ]
    }
   ],
   "source": [
    "it = iter(dl)\n",
    "xs,ys,lens =  next(it)\n",
    "print(type(xs))\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_PAD',\n",
       " '_UNK',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'i',\n",
       " 'to',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " 'that',\n",
       " 'you',\n",
       " '-',\n",
       " 'for',\n",
       " 'are',\n",
       " 'have',\n",
       " 'on',\n",
       " 'they',\n",
       " '?',\n",
       " 'this',\n",
       " 'white',\n",
       " '!',\n",
       " \"'s\",\n",
       " '`',\n",
       " 'with',\n",
       " 'was',\n",
       " 'my',\n",
       " 'do',\n",
       " 'all',\n",
       " 'be',\n",
       " 'not',\n",
       " 'but',\n",
       " 'as',\n",
       " 'like',\n",
       " 'we',\n",
       " 'or',\n",
       " 'if',\n",
       " 'there',\n",
       " \"n't\",\n",
       " 'their',\n",
       " ':',\n",
       " 'just',\n",
       " \"'\",\n",
       " 'at',\n",
       " 'will',\n",
       " 'from',\n",
       " 'so',\n",
       " 'your',\n",
       " 'out',\n",
       " 'people',\n",
       " 'them',\n",
       " ')',\n",
       " 'about',\n",
       " '(',\n",
       " 'can',\n",
       " 'me',\n",
       " 'up',\n",
       " '...',\n",
       " 'would',\n",
       " 'one',\n",
       " \"''\",\n",
       " 'get',\n",
       " '*',\n",
       " 'who',\n",
       " 'youtube',\n",
       " 'here',\n",
       " 'what',\n",
       " 'when',\n",
       " 'by',\n",
       " '/',\n",
       " 'no',\n",
       " 'our',\n",
       " 'some',\n",
       " 'black',\n",
       " 'more',\n",
       " 'an',\n",
       " 'see',\n",
       " 'good',\n",
       " 'm',\n",
       " 'he',\n",
       " 'has',\n",
       " 'whites',\n",
       " 'know',\n",
       " 'how',\n",
       " 'go',\n",
       " 'been',\n",
       " 'other',\n",
       " 'time',\n",
       " 'nt',\n",
       " 'think',\n",
       " 'were',\n",
       " 'had',\n",
       " 'then',\n",
       " 'only',\n",
       " 'her',\n",
       " 'new',\n",
       " 'school',\n",
       " 'these',\n",
       " 'should',\n",
       " 'back',\n",
       " 'any',\n",
       " 'want',\n",
       " 'because',\n",
       " 'say',\n",
       " 'than',\n",
       " 'few',\n",
       " 'well',\n",
       " 'those',\n",
       " 'us',\n",
       " 'now',\n",
       " 'race',\n",
       " 'many',\n",
       " 'too',\n",
       " 'old',\n",
       " 'day',\n",
       " 'very',\n",
       " 'his',\n",
       " 'way',\n",
       " 'got',\n",
       " 'kids',\n",
       " 'its',\n",
       " 'where',\n",
       " 'years',\n",
       " 'around',\n",
       " 'she',\n",
       " 'even',\n",
       " 'over',\n",
       " 'into',\n",
       " 'never',\n",
       " '&',\n",
       " 'did',\n",
       " 'could',\n",
       " 'blacks',\n",
       " 'am',\n",
       " '=',\n",
       " 'need',\n",
       " 'down',\n",
       " 'every',\n",
       " 'going',\n",
       " 'great',\n",
       " 'year',\n",
       " 'same',\n",
       " 'video',\n",
       " 'find',\n",
       " 'look',\n",
       " 'also',\n",
       " 'make',\n",
       " '%',\n",
       " 'anyone',\n",
       " 'country',\n",
       " 'own',\n",
       " 'live',\n",
       " 'much',\n",
       " 'most',\n",
       " 'last',\n",
       " 'being',\n",
       " ';',\n",
       " 'first',\n",
       " \"'re\",\n",
       " 've',\n",
       " 'hope',\n",
       " 'why',\n",
       " \"'ll\",\n",
       " '..',\n",
       " 'looking',\n",
       " 'always',\n",
       " 'him',\n",
       " 'off',\n",
       " 'world',\n",
       " 'right',\n",
       " 'show',\n",
       " 'take',\n",
       " 'non',\n",
       " 'news',\n",
       " 'home',\n",
       " 'thread',\n",
       " 'ever',\n",
       " 'two',\n",
       " 'watch',\n",
       " 's',\n",
       " 'which',\n",
       " 'let',\n",
       " 'thing',\n",
       " 'post',\n",
       " 'does',\n",
       " ']',\n",
       " '[',\n",
       " 'jews',\n",
       " 'put',\n",
       " 'before',\n",
       " 'come',\n",
       " 'ireland',\n",
       " 'said',\n",
       " 'man',\n",
       " 'something',\n",
       " 'ca',\n",
       " 'really',\n",
       " 'ago',\n",
       " 'little',\n",
       " 'children',\n",
       " 'maybe',\n",
       " 'after',\n",
       " 'area',\n",
       " 'anything',\n",
       " 'long',\n",
       " 'saw',\n",
       " 'nothing',\n",
       " 'times',\n",
       " 'someone',\n",
       " 'read',\n",
       " 'start',\n",
       " 'another',\n",
       " 'https',\n",
       " 'thank',\n",
       " 'yes',\n",
       " 'seen',\n",
       " 'went',\n",
       " 'use',\n",
       " 'talk',\n",
       " 'free',\n",
       " 'still',\n",
       " 'place',\n",
       " '2',\n",
       " 'irish',\n",
       " \"'m\",\n",
       " '_',\n",
       " 'try',\n",
       " 'while',\n",
       " 'negro',\n",
       " 'against',\n",
       " 'site',\n",
       " 'person',\n",
       " 'eyes',\n",
       " 'found',\n",
       " 'bad',\n",
       " '....',\n",
       " 'hate',\n",
       " 'forum',\n",
       " \"'d\",\n",
       " 'work',\n",
       " 'sure',\n",
       " 'keep',\n",
       " 'friends',\n",
       " 'such',\n",
       " 'please',\n",
       " 'again',\n",
       " 'anti',\n",
       " 'heard',\n",
       " 'jew',\n",
       " 'since',\n",
       " 'group',\n",
       " 'town',\n",
       " 'women',\n",
       " 'actually',\n",
       " 'give',\n",
       " 'god',\n",
       " 'next',\n",
       " 'feel',\n",
       " 'name',\n",
       " 'city',\n",
       " 'schools',\n",
       " 'guy',\n",
       " 'house',\n",
       " 'girl',\n",
       " 'tv',\n",
       " 'things',\n",
       " 'love',\n",
       " '1',\n",
       " 'thanks',\n",
       " 'nationalist',\n",
       " 'family',\n",
       " 'made',\n",
       " 'hair',\n",
       " 'pm',\n",
       " 'must',\n",
       " 'welcome',\n",
       " 'better',\n",
       " '|',\n",
       " 'brown',\n",
       " 'else',\n",
       " 'big',\n",
       " '$',\n",
       " 'may',\n",
       " 'far',\n",
       " 'away',\n",
       " 'part',\n",
       " 'high',\n",
       " 'wonder',\n",
       " 'american',\n",
       " 'tell',\n",
       " 'english',\n",
       " 'lot',\n",
       " 'africa',\n",
       " 'trying',\n",
       " 'stop',\n",
       " 'racist',\n",
       " 'thought',\n",
       " 'once',\n",
       " 'days',\n",
       " 'woman',\n",
       " 'today',\n",
       " 'music',\n",
       " 'money',\n",
       " 'used',\n",
       " 'life',\n",
       " 'together',\n",
       " 'looks',\n",
       " 'stormfront',\n",
       " 'came',\n",
       " 'through',\n",
       " 'week',\n",
       " 'left',\n",
       " 'hell',\n",
       " 'check',\n",
       " '#',\n",
       " 'probably',\n",
       " 'pretty',\n",
       " 'meet',\n",
       " 'help',\n",
       " 'enough',\n",
       " 'best',\n",
       " '3',\n",
       " 'hey',\n",
       " 'men',\n",
       " 'police',\n",
       " 'crime',\n",
       " 'believe',\n",
       " 'guess',\n",
       " 'different',\n",
       " 'public',\n",
       " 'government',\n",
       " 'though',\n",
       " 'nice',\n",
       " 'until',\n",
       " 'half',\n",
       " 'living',\n",
       " 'europe',\n",
       " 'etc',\n",
       " 'link',\n",
       " 'send',\n",
       " 'jewish',\n",
       " 'says',\n",
       " 'everyone',\n",
       " 'hear',\n",
       " 'couple',\n",
       " 'problem',\n",
       " 'fight',\n",
       " 'soon',\n",
       " 'least',\n",
       " 'story',\n",
       " 'canada',\n",
       " 'each',\n",
       " 'child',\n",
       " 'called',\n",
       " 'college',\n",
       " 'themselves',\n",
       " '5',\n",
       " 'hard',\n",
       " 'yet',\n",
       " 'small',\n",
       " 'become',\n",
       " 'south',\n",
       " 'coming',\n",
       " 'lol',\n",
       " 'told',\n",
       " 'skin',\n",
       " 'doing',\n",
       " 'support',\n",
       " 'stupid',\n",
       " 'truth',\n",
       " 'beautiful',\n",
       " 'makes',\n",
       " 'might',\n",
       " 'real',\n",
       " 'getting',\n",
       " 'color',\n",
       " 'nation',\n",
       " 'death',\n",
       " 'kid',\n",
       " 'attack',\n",
       " 'girls',\n",
       " 'done',\n",
       " 'point',\n",
       " 'message',\n",
       " 'teachers',\n",
       " 'front',\n",
       " 'history',\n",
       " 'culture',\n",
       " 'parents',\n",
       " 'care',\n",
       " 'end',\n",
       " 'night',\n",
       " 'state',\n",
       " 'whole',\n",
       " 'fact',\n",
       " 'asian',\n",
       " 'both',\n",
       " 'media',\n",
       " 'yourself',\n",
       " 'german',\n",
       " 'seems',\n",
       " 'young',\n",
       " 'move',\n",
       " 'word',\n",
       " 'without',\n",
       " 'london',\n",
       " 'full',\n",
       " 'countries',\n",
       " 'wait',\n",
       " 'run',\n",
       " \"'ve\",\n",
       " 'yeah',\n",
       " 'weeks',\n",
       " 'idea',\n",
       " 'alone',\n",
       " 'true',\n",
       " 'asians',\n",
       " 'u',\n",
       " 'call',\n",
       " 'having',\n",
       " 'reason',\n",
       " 'able',\n",
       " 'teacher',\n",
       " 'open',\n",
       " 'under',\n",
       " 'guys',\n",
       " 'kind',\n",
       " 'future',\n",
       " 'light',\n",
       " 'hi',\n",
       " '//www.stormfront.org',\n",
       " 'war',\n",
       " 'stuff',\n",
       " 'america',\n",
       " 'others',\n",
       " 'cause',\n",
       " 'boy',\n",
       " 'join',\n",
       " 'mean',\n",
       " 'blue',\n",
       " 'almost',\n",
       " 'water',\n",
       " 'european',\n",
       " 'mother',\n",
       " 'blood',\n",
       " 'community',\n",
       " 'goes',\n",
       " 'proud',\n",
       " 'racial',\n",
       " '--',\n",
       " 'remember',\n",
       " 'sorry',\n",
       " 'learn',\n",
       " 'picture',\n",
       " 'lots',\n",
       " 'speak',\n",
       " 'everything',\n",
       " 'videos',\n",
       " 'negroes',\n",
       " 'between',\n",
       " 'food',\n",
       " '4',\n",
       " 'party',\n",
       " 'already',\n",
       " 'students',\n",
       " 'during',\n",
       " 'friend',\n",
       " 'wrong',\n",
       " 'wo',\n",
       " 'watching',\n",
       " 'pride',\n",
       " 'crap',\n",
       " 'gets',\n",
       " 'turn',\n",
       " 'oh',\n",
       " 'job',\n",
       " 'leave',\n",
       " 'ones',\n",
       " 'stay',\n",
       " 'across',\n",
       " 'class',\n",
       " 'county',\n",
       " 'happy',\n",
       " 'line',\n",
       " 'face',\n",
       " 'shows',\n",
       " 'along',\n",
       " 'behind',\n",
       " '100',\n",
       " 'brothers',\n",
       " 'gun',\n",
       " 'mixed',\n",
       " 'st',\n",
       " 'wanted',\n",
       " 'myself',\n",
       " 'pictures',\n",
       " 'french',\n",
       " 'band',\n",
       " 'book',\n",
       " 'dr',\n",
       " 'talking',\n",
       " 'either',\n",
       " 'head',\n",
       " 'working',\n",
       " 'comes',\n",
       " '88',\n",
       " 'sf',\n",
       " 'started',\n",
       " 'youth',\n",
       " 'saying',\n",
       " 'dark',\n",
       " 'posted',\n",
       " 'sweden',\n",
       " 'hello',\n",
       " 'side',\n",
       " 'members',\n",
       " 'ya',\n",
       " 'march',\n",
       " 'sad',\n",
       " 'pass',\n",
       " 'land',\n",
       " '2508',\n",
       " 'song',\n",
       " 'near',\n",
       " 'using',\n",
       " 'guns',\n",
       " 'took',\n",
       " 'age',\n",
       " 'male',\n",
       " 'murder',\n",
       " 'matter',\n",
       " 'wants',\n",
       " '10',\n",
       " 'law',\n",
       " 'internet',\n",
       " 'poor',\n",
       " 'rest',\n",
       " 'christian',\n",
       " 'british',\n",
       " 'local',\n",
       " 'genocide',\n",
       " 'later',\n",
       " '6',\n",
       " 'online',\n",
       " 'liberal',\n",
       " 'stand',\n",
       " 'exactly',\n",
       " '.....',\n",
       " 'page',\n",
       " 'v',\n",
       " 'university',\n",
       " 'teach',\n",
       " 'power',\n",
       " 'tried',\n",
       " 'sent',\n",
       " 'change',\n",
       " 'information',\n",
       " 'gone',\n",
       " 'course',\n",
       " 'hand',\n",
       " 'red',\n",
       " 'funny',\n",
       " 'father',\n",
       " 'races',\n",
       " 'posting',\n",
       " 'sound',\n",
       " 'several',\n",
       " 'single',\n",
       " 'taken',\n",
       " 'nordic',\n",
       " 't',\n",
       " 'son',\n",
       " 'mind',\n",
       " 'd',\n",
       " '30',\n",
       " 'places',\n",
       " 'scum',\n",
       " 'killed',\n",
       " 'ok',\n",
       " '20',\n",
       " 'rather',\n",
       " 'moved',\n",
       " 'means',\n",
       " 'ask',\n",
       " 'happened',\n",
       " 'wish',\n",
       " 'western',\n",
       " 'dirty',\n",
       " 'national',\n",
       " 'three',\n",
       " 'brother',\n",
       " 'set',\n",
       " 'close',\n",
       " 'system',\n",
       " 'usually',\n",
       " 'shot',\n",
       " 'dead',\n",
       " 'board',\n",
       " 'liberals',\n",
       " 'street',\n",
       " '/td',\n",
       " 'green',\n",
       " 'info',\n",
       " 'kill',\n",
       " 'die',\n",
       " 'texas',\n",
       " 'minority',\n",
       " 'eat',\n",
       " 'earth',\n",
       " 'listen',\n",
       " 'making',\n",
       " 'wn',\n",
       " 'groups',\n",
       " 'past',\n",
       " 'case',\n",
       " 'pro',\n",
       " 'understand',\n",
       " 'article',\n",
       " 'report',\n",
       " 'knows',\n",
       " 'david',\n",
       " 'website',\n",
       " 'posts',\n",
       " 'anyway',\n",
       " 'immigrants',\n",
       " 'gay',\n",
       " 'quite',\n",
       " 'happen',\n",
       " 'york',\n",
       " 'click',\n",
       " 'interested',\n",
       " 'especially',\n",
       " 'section',\n",
       " 'none',\n",
       " 'knew',\n",
       " 'walk',\n",
       " 'england',\n",
       " 'type',\n",
       " 'words',\n",
       " 'month',\n",
       " 'example',\n",
       " 'radio',\n",
       " 'mine',\n",
       " 'looked',\n",
       " 'taking',\n",
       " 'outside',\n",
       " 'email',\n",
       " 'less',\n",
       " 'ple',\n",
       " 'instead',\n",
       " 'sometimes',\n",
       " 'interesting',\n",
       " 'important',\n",
       " 'football',\n",
       " 'months',\n",
       " 'buy',\n",
       " 'holocaust',\n",
       " 'thinking',\n",
       " 'above',\n",
       " 'dumb',\n",
       " 'disgusting',\n",
       " 'lived',\n",
       " 'nationalists',\n",
       " 'ð',\n",
       " 'anymore',\n",
       " 'population',\n",
       " 'hundreds',\n",
       " 'nations',\n",
       " 'problems',\n",
       " 'fighting',\n",
       " 'sick',\n",
       " 'cool',\n",
       " 'bit',\n",
       " '50',\n",
       " 'list',\n",
       " 'worse',\n",
       " 'sports',\n",
       " 'bunch',\n",
       " 'running',\n",
       " 'bring',\n",
       " 'hands',\n",
       " 'everywhere',\n",
       " 'israel',\n",
       " 'dog',\n",
       " 'north',\n",
       " 'round',\n",
       " 'fast',\n",
       " 'planet',\n",
       " 'lets',\n",
       " 'thousands',\n",
       " 'east',\n",
       " 'education',\n",
       " 'force',\n",
       " 'laugh',\n",
       " 'top',\n",
       " 'control',\n",
       " 'society',\n",
       " 'aryan',\n",
       " 'wife',\n",
       " 'mixing',\n",
       " 'order',\n",
       " 'pay',\n",
       " 'possible',\n",
       " 'f',\n",
       " 'jesus',\n",
       " 'indeed',\n",
       " 'perhaps',\n",
       " 'car',\n",
       " 'human',\n",
       " 'fear',\n",
       " 'sister',\n",
       " 'fish',\n",
       " 'action',\n",
       " 'immigration',\n",
       " 'luck',\n",
       " 'beat',\n",
       " 'agree',\n",
       " 'britain',\n",
       " 'mostly',\n",
       " 'sisters',\n",
       " 'caught',\n",
       " 'works',\n",
       " 'play',\n",
       " 'sounds',\n",
       " 'glad',\n",
       " 'reading',\n",
       " 'plan',\n",
       " 'pet',\n",
       " 'e',\n",
       " 'act',\n",
       " 'female',\n",
       " 'except',\n",
       " 'charged',\n",
       " 'killing',\n",
       " 'millions',\n",
       " 'alot',\n",
       " 'self',\n",
       " 'hours',\n",
       " 'animals',\n",
       " '+',\n",
       " 'member',\n",
       " 'diversity',\n",
       " 'imagine',\n",
       " 'n',\n",
       " 'west',\n",
       " '15',\n",
       " 'within',\n",
       " 'spread',\n",
       " 'early',\n",
       " 'according',\n",
       " 'judge',\n",
       " 'muslim',\n",
       " 'large',\n",
       " 'ethnic',\n",
       " 'short',\n",
       " 'lives',\n",
       " '9',\n",
       " 'summer',\n",
       " 'body',\n",
       " 'damn',\n",
       " 'number',\n",
       " 'however',\n",
       " 'respect',\n",
       " 'figure',\n",
       " 'follow',\n",
       " 'gave',\n",
       " 'among',\n",
       " 'chinese',\n",
       " 'game',\n",
       " 'social',\n",
       " 'evil',\n",
       " 'huge',\n",
       " 'built',\n",
       " 'na',\n",
       " 'books',\n",
       " 'clean',\n",
       " 'hit',\n",
       " '12',\n",
       " 'lost',\n",
       " 'movement',\n",
       " 'event',\n",
       " 'unfortunately',\n",
       " 'door',\n",
       " 'giving',\n",
       " 'whatever',\n",
       " 'create',\n",
       " 'save',\n",
       " 'cut',\n",
       " 'europeans',\n",
       " 'sort',\n",
       " 'continue',\n",
       " 'showing',\n",
       " 'late',\n",
       " 'bus',\n",
       " 'scene',\n",
       " 'five',\n",
       " 'seem',\n",
       " 'phone',\n",
       " 'mail',\n",
       " 'ground',\n",
       " 'middle',\n",
       " 'feet',\n",
       " '//petitions.whitehouse.gov',\n",
       " 'simply',\n",
       " 'download',\n",
       " 'movies',\n",
       " 'movie',\n",
       " '8',\n",
       " 'note',\n",
       " 'baby',\n",
       " 'bar',\n",
       " '14',\n",
       " 'americans',\n",
       " 'telling',\n",
       " '11',\n",
       " 'christmas',\n",
       " 'search',\n",
       " 'cross',\n",
       " 'similar',\n",
       " 'security',\n",
       " 'second',\n",
       " 'wow',\n",
       " 'california',\n",
       " 'propaganda',\n",
       " 'brought',\n",
       " 'metal',\n",
       " 'language',\n",
       " 'drug',\n",
       " 'add',\n",
       " 'below',\n",
       " 'million',\n",
       " 'stick',\n",
       " 'african',\n",
       " 'given',\n",
       " 'four',\n",
       " 'grow',\n",
       " 'happens',\n",
       " 'heritage',\n",
       " 'victims',\n",
       " 'violent',\n",
       " 'duke',\n",
       " 'moment',\n",
       " 'attention',\n",
       " 'common',\n",
       " 'company',\n",
       " 'third',\n",
       " 'slavic',\n",
       " 'morning',\n",
       " 'northern',\n",
       " 'broadcast',\n",
       " 'version',\n",
       " 'comment',\n",
       " 'lady',\n",
       " 'folks',\n",
       " 'major',\n",
       " 'families',\n",
       " 'based',\n",
       " '25',\n",
       " 'hide',\n",
       " 'tree',\n",
       " 'majority',\n",
       " 'hopefully',\n",
       " 're',\n",
       " 'sign',\n",
       " '\"',\n",
       " 'fun',\n",
       " 'san',\n",
       " 'wondering',\n",
       " 'bet',\n",
       " 'numbers',\n",
       " 'test',\n",
       " 'civilization',\n",
       " 'hour',\n",
       " 'account',\n",
       " 'gods',\n",
       " '......',\n",
       " 'playing',\n",
       " 'church',\n",
       " 'mr',\n",
       " 'arrested',\n",
       " 'enemies',\n",
       " 'drink',\n",
       " 'apes',\n",
       " 'x202a',\n",
       " 'x202c',\n",
       " 'photo',\n",
       " 'russia',\n",
       " 'heart',\n",
       " 'cheap',\n",
       " 'enjoy',\n",
       " 'russian',\n",
       " 'student',\n",
       " 'met',\n",
       " 'swedish',\n",
       " 'celtic',\n",
       " 'cities',\n",
       " 'total',\n",
       " 'germany',\n",
       " 'forward',\n",
       " 'lie',\n",
       " 'mention',\n",
       " 'poland',\n",
       " 'mass',\n",
       " '·',\n",
       " 'throw',\n",
       " 'mud',\n",
       " 'channel',\n",
       " 'hoping',\n",
       " 'southern',\n",
       " 'boys',\n",
       " 'william',\n",
       " 'dogs',\n",
       " 'forced',\n",
       " 'chicago',\n",
       " 'shame',\n",
       " 'hang',\n",
       " 'allowed',\n",
       " 'including',\n",
       " 'favorite',\n",
       " 'often',\n",
       " 'moving',\n",
       " 'hitler',\n",
       " 'worth',\n",
       " 'per',\n",
       " 'shooting',\n",
       " 'surprised',\n",
       " 'seeing',\n",
       " 'sitting',\n",
       " 'paper',\n",
       " 'till',\n",
       " 'recently',\n",
       " 'ukraine',\n",
       " 'hispanic',\n",
       " 'somewhere',\n",
       " 'daughter',\n",
       " 'o',\n",
       " 'born',\n",
       " 'happening',\n",
       " 'decided',\n",
       " 'ill',\n",
       " 'likely',\n",
       " 'dna',\n",
       " 'shoot',\n",
       " 'longer',\n",
       " 'question',\n",
       " 'pick',\n",
       " 'minister',\n",
       " 'nationalism',\n",
       " 'babies',\n",
       " 'straight',\n",
       " 'events',\n",
       " 'gon',\n",
       " 'nature',\n",
       " 'certain',\n",
       " 'wake',\n",
       " 'eating',\n",
       " 'promote',\n",
       " 'enemy',\n",
       " 'evidence',\n",
       " '^',\n",
       " 'strong',\n",
       " 'pierce',\n",
       " 'text',\n",
       " 'jobs',\n",
       " 'obama',\n",
       " 'military',\n",
       " 'christ',\n",
       " '21',\n",
       " 'criminal',\n",
       " 'humans',\n",
       " 'build',\n",
       " 'animal',\n",
       " 'joined',\n",
       " 'rlm',\n",
       " 'stories',\n",
       " 'norway',\n",
       " '7',\n",
       " 'nearly',\n",
       " 'apparently',\n",
       " 'doubt',\n",
       " 'camp',\n",
       " 'active',\n",
       " 'needs',\n",
       " 'genetic',\n",
       " 'ass',\n",
       " 'florida',\n",
       " 'plus',\n",
       " 'bible',\n",
       " 'itself',\n",
       " 'present',\n",
       " 'thousand',\n",
       " 'native',\n",
       " 'asked',\n",
       " 'art',\n",
       " 'claim',\n",
       " 'store',\n",
       " 'ape',\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext.datasets.text_classification' has no attribute 'ds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-c794934973f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m train_dataset, test_dataset = text_classification.ds(\n\u001b[0m\u001b[0;32m      6\u001b[0m     root='./.data', ngrams=NGRAMS, vocab=None)\n\u001b[0;32m      7\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchtext.datasets.text_classification' has no attribute 'ds'"
     ]
    }
   ],
   "source": [
    "NGRAMS = 2\n",
    "import os\n",
    "if not os.path.isdir('./.data'):\n",
    "    os.mkdir('./.data')\n",
    "train_dataset, test_dataset = text_classification(\n",
    "    root='./.data', ngrams=NGRAMS, vocab=None)\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(words)\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(df.label)\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    # torch.Tensor.cumsum returns the cumulative sum\n",
    "    # of elements in the dimension dim.\n",
    "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "\n",
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "tensor(6839)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f8cc9d19d248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_valid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-54284a622b1e>\u001b[0m in \u001b[0;36mtrain_func\u001b[1;34m(sub_train_)\u001b[0m\n\u001b[0;32m      8\u001b[0m     data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n\u001b[0;32m      9\u001b[0m                       collate_fn=generate_batch)\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-b85879f48820>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentimentpadded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4372\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4373\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4374\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4375\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: tensor(6839)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(ds) * 0.95)\n",
    "sub_train_, sub_valid_ = \\\n",
    "    random_split(ds, [train_len, len(ds) - train_len])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
