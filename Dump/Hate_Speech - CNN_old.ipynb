{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment(file):\n",
    "    mydir = 'C:\\\\Users\\\\Sandesh\\\\Desktop\\\\hate-speech-dataset\\\\all_files'\n",
    "    with open(os.path.join(mydir,file+\".txt\"), 'r', encoding='utf8') as f:\n",
    "        return f.read().lower()\n",
    "    return\n",
    "\n",
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "def append_comment(df,column_name):\n",
    "    df[column_name] = df['file_id'].apply(lambda x:get_comment(x))\n",
    "    return df\n",
    "\n",
    "def create_mapping(df):\n",
    "    labels = df.label.unique()\n",
    "    mapping = {}\n",
    "    for idx,val in enumerate(labels):\n",
    "        mapping[val] = idx\n",
    "    return mapping\n",
    "\n",
    "def set_numeric_label(df):\n",
    "    mapping = create_mapping(df)\n",
    "    df['new_label'] = df['label'].apply(lambda s: mapping.get(s))\n",
    "    return df  \n",
    "\n",
    "def prepare_dataset():\n",
    "    file = \"C:/Users/Sandesh/Desktop/hate-speech-dataset/annotations_metadata.csv\"\n",
    "    df = load_data(file)\n",
    "    df = append_comment(df,'text')\n",
    "    df = set_numeric_label(df)\n",
    "    return df\n",
    "\n",
    "# mydir = 'C:\\\\Users\\\\Sandesh\\\\Desktop\\\\hate-speech-dataset\\\\all_files'\n",
    "# df =pd.read_csv(\"C:/Users/Sandesh/Desktop/hate-speech-dataset/annotations_metadata.csv\")\n",
    "# df['text'] = df['file_id'].apply(lambda x:get_comment(x))\n",
    "\n",
    "# mapping = {'noHate': 0, 'hate':1, 'relation':2,'idk/skip':3 }\n",
    "# df['new_label'] = df['label'].apply(lambda s: mapping.get(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without using Relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the sentences labelled as `HATE` have been collected, and an equivalent number of `NOHATE` sentences have been randomly\n",
    "sampled, summing up 2k labelled sentences. \n",
    "\n",
    "Training: Test split = 80%:20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[(df[\"label\"]=='hate') | (df[\"label\"]=='noHate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[(df1['text'].apply(lambda x: len(x.split()))>=3) & (df1['text'].apply(lambda x: len(x.split()))<=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_hate = df2[df2['label']=='hate']\n",
    "df2_noHate = df2[df2['label']=='noHate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1154, 8869)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2_hate), len(df2_noHate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balance the hate and noHate count \n",
    "sample_hate = df2_hate.sample(1000)\n",
    "sample_nohate = df2_noHate.sample(1000)\n",
    "new_df = pd.concat([sample_hate, sample_nohate], axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_new = shuffle(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_count=new_df.groupby('label').count()\n",
    "plt.bar(label_count.index.values, label_count['text'])\n",
    "plt.xlabel('Review Sentiments')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(X_train,X_test):\n",
    "    vocab = Counter()\n",
    "    for text in X_train:\n",
    "        for word in text.strip().split(' '):\n",
    "            vocab[word.lower()]+=1\n",
    "    for text in X_test:\n",
    "        for word in text.strip().split(' '):\n",
    "            vocab[word.lower()]+=1\n",
    "    return vocab\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "    return word2index\n",
    "\n",
    "def get_batch(X_data,y,i,batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    texts = X_data[i*batch_size:i*batch_size+batch_size]\n",
    "    categories = y[i*batch_size:i*batch_size+batch_size]\n",
    "    for text in texts:\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "\n",
    "        batches.append(layer)\n",
    "\n",
    "    for category in categories:\n",
    "        index_y = -1\n",
    "        if category == 0:\n",
    "            index_y = 0\n",
    "        else:\n",
    "            index_y = 1\n",
    "        results.append(index_y)\n",
    "        \n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class OurNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(OurNet, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test split\n",
    "X = df_new.text\n",
    "y = df_new.new_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab(X_train,X_test)\n",
    "total_words = len(vocab)\n",
    "word2index = get_word_2_index(vocab)\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 150\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "hidden_size = 100      # 1st layer and 2nd layer number of features\n",
    "input_size = total_words # Words in vocab\n",
    "num_classes = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches :  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [4/10], Loss: 0.6445\n",
      "Epoch [1/10], Step [8/10], Loss: 0.6336\n",
      "Epoch [2/10], Step [4/10], Loss: 0.2442\n",
      "Epoch [2/10], Step [8/10], Loss: 0.1374\n",
      "Epoch [3/10], Step [4/10], Loss: 0.0738\n",
      "Epoch [3/10], Step [8/10], Loss: 0.0285\n",
      "Epoch [4/10], Step [4/10], Loss: 0.0092\n",
      "Epoch [4/10], Step [8/10], Loss: 0.0006\n",
      "Epoch [5/10], Step [4/10], Loss: 0.0088\n",
      "Epoch [5/10], Step [8/10], Loss: 0.0002\n",
      "Epoch [6/10], Step [4/10], Loss: 0.0001\n",
      "Epoch [6/10], Step [8/10], Loss: 0.0001\n",
      "Epoch [7/10], Step [4/10], Loss: 0.0002\n",
      "Epoch [7/10], Step [8/10], Loss: 0.0001\n",
      "Epoch [8/10], Step [4/10], Loss: 0.0000\n",
      "Epoch [8/10], Step [8/10], Loss: 0.0001\n",
      "Epoch [9/10], Step [4/10], Loss: 0.0000\n",
      "Epoch [9/10], Step [8/10], Loss: 0.0001\n",
      "Epoch [10/10], Step [4/10], Loss: 0.0000\n",
      "Epoch [10/10], Step [8/10], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "net = OurNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "print(\"Total batches : \",int(X_train.shape[0]/batch_size))\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    total_batch = int(X_train.shape[0]/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(X_train,y_train,i,batch_size)\n",
    "        articles = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        #print(\"articles\",articles)\n",
    "        #print(batch_x, labels)\n",
    "        #print(\"size labels\",labels.size())\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(articles)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 4 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, X_train.shape[0]//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network over test articles: 72 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "total_test_data = len(y_test)\n",
    "batch_x_test,batch_y_test = get_batch(X_test,y_test,0,total_test_data)\n",
    "articles = Variable(torch.FloatTensor(batch_x_test))\n",
    "labels = torch.LongTensor(batch_y_test)\n",
    "outputs = net(articles)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network over test articles: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146529562982006"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, predicted)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 2\n",
    "\n",
    "## Including relation as hatespeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noHate      9507\n",
       "hate        1196\n",
       "relation     168\n",
       "idk/skip      73\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df3 = df\n",
    "df3['label'][df3.label=='relation']= 'hate'\n",
    "df3 = set_numeric_label(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9507\n",
       "1    1364\n",
       "2      73\n",
       "Name: new_label, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['new_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noHate      9507\n",
       "hate        1364\n",
       "idk/skip      73\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1364, 9507)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_hate = df3[df3['label']=='hate']\n",
    "df3_noHate = df3[df3['label']=='noHate']\n",
    "len(df3_hate), len(df3_noHate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hate1 = df3_hate.sample(1000)\n",
    "sample_nohate1 = df3_noHate.sample(1000)\n",
    "\n",
    "new_df1 = pd.concat([sample_hate1, sample_nohate1], axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1 = shuffle(new_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_new1.text, df_new1.new_label, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab(X_train,X_test)\n",
    "total_words = len(vocab)\n",
    "word2index = get_word_2_index(vocab)\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 150\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "hidden_size = 100      # 1st layer and 2nd layer number of features\n",
    "input_size = total_words # Words in vocab\n",
    "num_classes = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches :  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [4/10], Loss: 0.6425\n",
      "Epoch [1/10], Step [8/10], Loss: 0.6391\n",
      "Epoch [2/10], Step [4/10], Loss: 0.2235\n",
      "Epoch [2/10], Step [8/10], Loss: 0.2149\n",
      "Epoch [3/10], Step [4/10], Loss: 0.0066\n",
      "Epoch [3/10], Step [8/10], Loss: 0.0567\n",
      "Epoch [4/10], Step [4/10], Loss: 0.0021\n",
      "Epoch [4/10], Step [8/10], Loss: 0.0125\n",
      "Epoch [5/10], Step [4/10], Loss: 0.0322\n",
      "Epoch [5/10], Step [8/10], Loss: 0.0202\n",
      "Epoch [6/10], Step [4/10], Loss: 0.0009\n",
      "Epoch [6/10], Step [8/10], Loss: 0.0015\n",
      "Epoch [7/10], Step [4/10], Loss: 0.0005\n",
      "Epoch [7/10], Step [8/10], Loss: 0.0020\n",
      "Epoch [8/10], Step [4/10], Loss: 0.0002\n",
      "Epoch [8/10], Step [8/10], Loss: 0.0011\n",
      "Epoch [9/10], Step [4/10], Loss: 0.0001\n",
      "Epoch [9/10], Step [8/10], Loss: 0.0009\n",
      "Epoch [10/10], Step [4/10], Loss: 0.0001\n",
      "Epoch [10/10], Step [8/10], Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "net = OurNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "print(\"Total batches : \",int(X_train.shape[0]/batch_size))\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    total_batch = int(X_train.shape[0]/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(X_train,y_train,i,batch_size)\n",
    "        articles = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        #print(\"articles\",articles)\n",
    "        #print(batch_x, labels)\n",
    "        #print(\"size labels\",labels.size())\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(articles)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 4 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, X_train.shape[0]//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network over test articles: 67 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "total_test_data = len(y_test)\n",
    "batch_x_test,batch_y_test = get_batch(X_test,y_test,0,total_test_data)\n",
    "articles = Variable(torch.FloatTensor(batch_x_test))\n",
    "labels = torch.LongTensor(batch_y_test)\n",
    "outputs = net(articles)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network over test articles: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
