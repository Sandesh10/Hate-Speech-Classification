{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"./Desktop/nepali-ner/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sandesh\\\\Desktop\\\\nepali-ner'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Sandesh\\\\Desktop\\\\nepali-ner\\\\\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Nepali NER for PERSON, ORGANIZATION, LOCATION\n",
    "    \n",
    "    Nepali BiLSTM CNN\n",
    "    \n",
    "    Author - Oyesh Mann Singh\n",
    "    Data - 05/03/2019\n",
    "'''\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(142)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "from torchtext import datasets\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import conll_eval as e\n",
    "import sys, unicodedata\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import csv\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_field = data.Field(tokenize=list, use_vocab=True, init_token='<init>', eos_token='<eos>')\n",
    "# label_field = data.Field(unk_token=None, init_token='<init>', eos_token='<eos>')\n",
    "\n",
    "def split_into_char(x):\n",
    "    return x.split()\n",
    "\n",
    "txt_field = data.Field(tokenize=list, use_vocab=True)\n",
    "pos_field = data.Field(unk_token=None)\n",
    "label_field = data.Field(unk_token=None)\n",
    "char_field = data.Field(unk_token='<unk>', sequential=False)\n",
    "graph_field = data.Field(unk_token='<unk>', sequential=False)\n",
    "\n",
    "fields = (('TEXT', txt_field),('POS', pos_field),('TAG', label_field))\n",
    "\n",
    "# root_path='../data/ner/nepaliner/after_stemming/'\n",
    "root_path='./data/ebiquity/sandesh/1/'\n",
    "\n",
    "train_ds, val_ds, test_ds = SequenceTaggingDataset.splits(path=root_path,\n",
    "                                                 fields=fields,\n",
    "                                                 separator='\\t',\n",
    "                                                 train='train.txt', validation='val.txt', test='test.txt')\n",
    "\n",
    "nep2vec = './embeddings/fasttext/'\n",
    "# nep2glove='../data/glove'\n",
    "nep2ft='./embeddings/fasttext/'\n",
    "\n",
    "# vec = vocab.Vectors(name='nep2vec_clean', cache=nep2vec)\n",
    "# vec = vocab.Vectors(name='nep2glove-stem.txt', cache=nep2glove)\n",
    "vec = vocab.Vectors(name='nep2ft.vec', cache=nep2ft)\n",
    "\n",
    "txt_field.build_vocab(train_ds, test_ds, val_ds, max_size=None, vectors=vec)\n",
    "label_field.build_vocab(train_ds.TAG, test_ds.TAG, val_ds.TAG)\n",
    "pos_field.build_vocab(train_ds.POS, test_ds.POS, val_ds.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text vocab =  12435\n",
      "Length of NER label vocab =  5\n",
      "Length of POS vocab =  69\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(txt_field.vocab)):\n",
    "#     print(txt_field.vocab.itos[i])\n",
    "\n",
    "print('Length of text vocab = ',len(txt_field.vocab))\n",
    "print('Length of NER label vocab = ',len(label_field.vocab))\n",
    "print('Length of POS vocab = ',len(pos_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '-', '.', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ो', 'ौ', '्', '।']\n",
      "63\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "char_list = []\n",
    "for each in train_ds.examples + test_ds.examples + val_ds.examples:\n",
    "    for x in each.TEXT:\n",
    "        char_list+=list(x)\n",
    "char_list = list(set(char_list))\n",
    "\n",
    "char_list.sort()\n",
    "\n",
    "print(char_list)\n",
    "\n",
    "char_field.build_vocab(char_list)\n",
    "char_vocab_length = len(char_field.vocab)\n",
    "print(len(char_field.vocab))\n",
    "print(len(char_list))\n",
    "\n",
    "with open(root_path+'characters.txt', 'w', encoding='utf-8') as f:\n",
    "    for item in char_list:\n",
    "        f.write(item+' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read character level file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '-', '.', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ो', 'ौ', '्', '।']\n",
      "Length of character vocab =  63\n"
     ]
    }
   ],
   "source": [
    "with open(root_path+'characters.txt', 'r', encoding='utf-8') as f:\n",
    "    char_list = f.read().strip().split()\n",
    "    print(char_list)\n",
    "    \n",
    "char_field.build_vocab(char_list)\n",
    "char_vocab_length = len(char_field.vocab)\n",
    "print('Length of character vocab = ',len(char_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635\n"
     ]
    }
   ],
   "source": [
    "# Create a file full of grapheme cluster and just read those\n",
    "from uniseg.graphemecluster import grapheme_clusters\n",
    "graph_list = []\n",
    "for each in train_ds.examples + test_ds.examples + val_ds.examples:\n",
    "    for x in each.TEXT:\n",
    "        graph_list+=list(grapheme_clusters(x))\n",
    "graph_list = list(set(graph_list))\n",
    "graph_list.sort()\n",
    "\n",
    "graph_field.build_vocab(graph_list)\n",
    "print(len(graph_field.vocab))\n",
    "graph_vocab_length = len(graph_field.vocab)\n",
    "# for i in range(0, len(graph_field.vocab)):\n",
    "#     print(i, graph_field.vocab.itos[i])\n",
    "\n",
    "with open(root_path+'grapheme.txt', 'w', encoding='utf-8') as f:\n",
    "    for item in graph_list:\n",
    "        f.write(item+' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read grapheme level file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '-', '.', 'ँ', 'ः', 'अ', 'अँ', 'अं', 'अि', 'आ', 'आँ', 'आं', 'इ', 'इँ', 'ई', 'ईं', 'उ', 'उँ', 'उं', 'उा', 'ऊ', 'ऋ', 'ए', 'एँ', 'एि', 'ऐ', 'ओ', 'औ', 'औँ', 'औं', 'क', 'कँ', 'कं', 'कः', 'का', 'काँ', 'कां', 'काे', 'कि', 'किँ', 'किं', 'किा', 'किी', 'की', 'कु', 'कुँ', 'कुं', 'कू', 'कृ', 'के', 'केा', 'केे', 'कै', 'को', 'कौ', 'कौं', 'क्', 'ख', 'खँ', 'खं', 'खा', 'खाँ', 'खां', 'खि', 'खिँ', 'खिं', 'खी', 'खु', 'खे', 'खेँ', 'खै', 'खो', 'खौं', 'ख्', 'ग', 'गं', 'गा', 'गाँ', 'गां', 'गि', 'गिँ', 'गि्', 'गी', 'गु', 'गुँ', 'गू', 'गृ', 'गे', 'गे्', 'गै', 'गो', 'गौ', 'ग्', 'घ', 'घा', 'घाँ', 'घि', 'घी', 'घु', 'घुँ', 'घुं', 'घे', 'घै', 'घो', 'घ्', 'ङ', 'ङि्', 'ङी', 'ङे', 'ङ्', 'च', 'चं', 'चा', 'चाँ', 'चि', 'चिा', 'ची', 'चु', 'चुँ', 'चू', 'चे', 'चेे', 'चै', 'चैा', 'चो', 'चौ', 'चौँ', 'चौं', 'च्', 'छ', 'छँ', 'छः', 'छा', 'छि', 'छी', 'छु', 'छू', 'छृ', 'छे', 'छै', 'छो', 'छौ', 'छौँ', 'छौं', 'छ्', 'ज', 'जं', 'जा', 'जाँ', 'जि', 'जिा', 'जि्', 'जी', 'जु', 'जू', 'जे', 'जै', 'जो', 'जोे', 'ज्', 'झ', 'झँि', 'झा', 'झि', 'झी', 'झु', 'झू', 'झे', 'झै', 'झैं', 'झो', 'झौ', 'झ्', 'ञ', 'ञा', 'ञि', 'ञ्', 'ट', 'टं', 'टा', 'टाँ', 'टि', 'टिं', 'टिी', 'टि्', 'टी', 'टीा', 'टीी', 'टीे', 'टु', 'टुं', 'टू', 'टे', 'टे्', 'टै', 'टैं', 'टो', 'टौ', 'टौं', 'ट्', 'ठ', 'ठा', 'ठाँ', 'ठि', 'ठी', 'ठू', 'ठे', 'ठै', 'ठो', 'ठौ', 'ठौं', 'ठ्', 'ड', 'डं', 'डा', 'डाँ', 'डाै', 'डि', 'डि्', 'डी', 'डु', 'डुं', 'डे', 'डै', 'डो', 'डौ', 'डौँ', 'डौं', 'ड्', 'ढ', 'ढं', 'ढा', 'ढाँ', 'ढि', 'ढी', 'ढु', 'ढुं', 'ढू', 'ढे', 'ढो', 'ढोँ', 'ढ्', 'ण', 'णा', 'णाा', 'णि', 'णी', 'णु', 'णे', 'णो', 'ण्', 'ण्िा', 'ण्िाा', 'त', 'तँ', 'तँे', 'तं', 'तः', 'ता', 'ताँ', 'ति', 'तिा', 'ती', 'तु', 'तू', 'तृ', 'ते', 'तै', 'तैं', 'तो', 'तौ', 'तौँ', 'तौं', 'त्', 'त्ि', 'त्िा', 'थ', 'था', 'थाः', 'थि', 'थी', 'थु', 'थुं', 'थे', 'थे्', 'थै', 'थो', 'थ्', 'द', 'दँ', 'दं', 'दा', 'दाँ', 'दि', 'दिँ', 'दिं', 'दि्', 'दी', 'दु', 'दुः', 'दू', 'दृ', 'दे', 'दै', 'दो', 'दौ', 'द्', 'ध', 'धँ', 'धा', 'धाँ', 'धि', 'धी', 'धु', 'धु्', 'धू', 'धृ', 'धे', 'धै', 'धैँ', 'धैं', 'धो', 'धौ', 'ध्', 'न', 'नँ', 'नँै', 'नं', 'नः', 'ना', 'नां', 'नि', 'निँ', 'निः', 'निा', 'निु', 'निे', 'नि्', 'नी', 'नु', 'नू', 'नृ', 'ने', 'नेँ', 'नें', 'नै', 'नो', 'नौ', 'नौँ', 'नौं', 'न्', 'प', 'पं', 'पा', 'पाँ', 'पां', 'पि', 'पिँ', 'पि्', 'पी', 'पु', 'पुँ', 'पू', 'पूँ', 'पूं', 'पृ', 'पे', 'पै', 'पैं', 'पो', 'पौ', 'प्', 'फ', 'फा', 'फाँ', 'फि', 'फी', 'फु', 'फू', 'फे', 'फै', 'फैँ', 'फैं', 'फो', 'फौ', 'फ्', 'ब', 'बं', 'बा', 'बाँ', 'बां', 'बि', 'बिे', 'बि्', 'बी', 'बु', 'बुँ', 'बू', 'बृ', 'बे', 'बै', 'बैँ', 'बैं', 'बो', 'बौ', 'ब्', 'भ', 'भं', 'भा', 'भाँ', 'भि', 'भिा', 'भी', 'भु', 'भू', 'भृ', 'भे', 'भै', 'भो', 'भों', 'भौ', 'भौं', 'भ्', 'भ्ः', 'म', 'मं', 'मः', 'मा', 'माँ', 'मां', 'माा', 'मि', 'मिा', 'मी', 'मु', 'मू', 'मृ', 'मे', 'मै', 'मो', 'मौ', 'म्', 'य', 'यँ', 'यं', 'यः', 'या', 'याँ', 'यां', 'यि', 'यिा', 'यिो', 'यी', 'यु', 'युँ', 'यू', 'ये', 'यै', 'यो', 'यौ', 'यौँ', 'यौं', 'य्', 'र', 'रँ', 'रँे', 'रं', 'रा', 'राँ', 'रां', 'रि', 'रिँ', 'रिं', 'रिि', 'रिे', 'रि्', 'री', 'रु', 'रुं', 'रू', 'रृ', 'रे', 'रेँ', 'रें', 'रे्', 'रै', 'रो', 'रौ', 'रौँ', 'रौं', 'र्', 'र्ँ', 'र्ं', 'र्ा', 'र्ाा', 'र्ी', 'र्ीी', 'र्ु', 'र्ुु', 'र्ू', 'र्े', 'र्ै', 'र््', 'ल', 'लं', 'ला', 'लाँ', 'लि', 'लिँ', 'लिं', 'लिा', 'लिो', 'ली', 'लु', 'लुँ', 'लू', 'ले', 'लै', 'लैं', 'लो', 'लौ', 'ल्', 'ल्ा', 'व', 'वं', 'वः', 'वा', 'वाँ', 'वां', 'वि', 'विा', 'विे', 'वी', 'वु', 'वृ', 'वे', 'वै', 'वो', 'वौ', 'वौं', 'व्', 'श', 'शं', 'शः', 'शा', 'शां', 'शि', 'शिं', 'शी', 'शु', 'शू', 'शृ', 'शृं', 'शे', 'शै', 'शो', 'शौ', 'शौं', 'श्', 'ष', 'षा', 'षाँ', 'षि', 'षी', 'षुँ', 'षे', 'षेँ', 'षै', 'षो', 'षों', 'षौ', 'षौं', 'ष्', 'ष्ँ', 'ष्ँा', 'ष्ँी', 'ष्ा', 'ष्िा', 'स', 'सँ', 'सं', 'सा', 'साँ', 'सां', 'सि', 'सिँ', 'सिं', 'सिा', 'सिो', 'सि्', 'सी', 'सु', 'सू', 'सृ', 'से', 'सै', 'सैं', 'सैा', 'सो', 'सौ', 'सौं', 'स्', 'स्ि', 'ह', 'हँ', 'हं', 'हा', 'हाँ', 'हां', 'हि', 'हिँ', 'हिं', 'हिा', 'ही', 'हीँ', 'हीं', 'हु', 'हुँ', 'हुं', 'हुा', 'हू', 'हृ', 'हे', 'हे्', 'है', 'हो', 'हौ', 'हौँ', 'हौं', 'ह्', 'ि', 'ी', 'ै', '।']\n",
      "Length of grapheme vocab =  644\n"
     ]
    }
   ],
   "source": [
    "# Create a file full of grapheme cluster and just read those\n",
    "from uniseg.graphemecluster import grapheme_clusters\n",
    "with open(root_path+'grapheme.txt', 'r', encoding='utf-8') as f:\n",
    "    graph_list = f.read().strip().split()\n",
    "    print(graph_list)\n",
    "    \n",
    "graph_list += char_list\n",
    "graph_list = set(graph_list)\n",
    "    \n",
    "graph_field.build_vocab(graph_list)\n",
    "graph_vocab_length = len(graph_field.vocab)\n",
    "print('Length of grapheme vocab = ',len(graph_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify the batch data\n",
    "def idxtosent(batch, idx):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given batch and index\n",
    "    '''      \n",
    "    return ' '.join([txt_field.vocab.itos[i] for i in batch.TEXT[idx].cpu().data.numpy()])\n",
    "\n",
    "\n",
    "def idxtotag(batch, idx):\n",
    "    '''\n",
    "        Returns the corresponding TAG of given batch and index\n",
    "    '''     \n",
    "    return ' '.join([label_field.vocab.itos[i] for i in batch.TAG[idx].cpu().data.numpy()])\n",
    "\n",
    "\n",
    "def tensortosent(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''     \n",
    "    return ' '.join([txt_field.vocab.itos[i] for i in tense.cpu().data.numpy()])\n",
    "\n",
    "def tensortopos(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''     \n",
    "    return ' '.join([pos_field.vocab.itos[i] for i in tense.cpu().data.numpy()])\n",
    "\n",
    "def tensortotag(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''     \n",
    "    return ' '.join([label_field.vocab.itos[i] for i in tense.cpu().data.numpy()])\n",
    "\n",
    "def tensorToOneHot(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''\n",
    "    try:\n",
    "        return pos_one_hot[tense.cpu().data.numpy()]\n",
    "    except ValueError:\n",
    "        return pos_one_host[-1]\n",
    "\n",
    "\n",
    "def NumpyToSent(tensor):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given Predictions\n",
    "        Returns chunks of string\n",
    "    '''    \n",
    "    return ' '.join([txt_field.vocab.itos[i[0]] for i in tensor.cpu().data.numpy()]).split()\n",
    "\n",
    "\n",
    "def PredToTag(predictions):\n",
    "    '''\n",
    "        Returns the corresponding TAGS of given Predictions\n",
    "        Returns chunks of string\n",
    "    '''\n",
    "    return ' '.join([label_field.vocab.itos[i] for i in predictions]).split()\n",
    "\n",
    "# Because len(pos) = 56 and len(pos_field.vocab) = 55\n",
    "n_values=len(pos_field.vocab)+2\n",
    "pos_one_hot = np.eye(n_values)\n",
    "one_hot_weight = torch.from_numpy(pos_one_hot).float()\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, dl, x_field, y_field, z_field):\n",
    "        self.dl, self.x_field, self.y_field, self.z_field = dl, x_field, y_field, z_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x_field)\n",
    "            y = getattr(batch, self.y_field)\n",
    "            z = getattr(batch, self.z_field)\n",
    "            yield ((X,y), z)\n",
    "\n",
    "def plot_loss(train_loss, val_loss, title):\n",
    "    plt.figure(figsize=[8,5])\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.legend(['Training loss', 'Validation loss'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def save_checkpoint(model, opt, train_loss, train_acc, val_loss, val_acc, filename, epochs):\n",
    "    save_parameters = {'model': model,\n",
    "                       'state_dict':model.state_dict(),\n",
    "                       'opt':opt,\n",
    "                       'opt_state': opt.state_dict(),\n",
    "                      'train_loss' : train_loss,\n",
    "                      'train_acc' : train_acc,\n",
    "                      'val_loss' : val_loss,\n",
    "                      'val_acc' : val_acc,\n",
    "                      'epochs' : epochs}\n",
    "    torch.save(save_parameters, filename)\n",
    "    \n",
    "    \n",
    "def load_checkpoint(filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    opt = checkpoint['opt']\n",
    "    opt.load_state_dict(checkpoint['opt_state'])\n",
    "    train_loss = checkpoint['train_loss']\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    epochs = checkpoint['epochs']\n",
    "    \n",
    "    return model, opt, train_loss, train_acc, val_loss, val_acc, epochs\n",
    "\n",
    "def fit(model, train_dl, val_dl, loss_fn, opt, start_epoch, lstm_model_file, epochs=1):\n",
    "    total_train_loss = []\n",
    "    total_train_acc = []\n",
    "    total_val_loss = []\n",
    "    total_val_acc = []\n",
    "    num_batch = len(train_dl)\n",
    "    prev_lstm_val_acc=0.0\n",
    "    prev_val_loss=100.0\n",
    "    counter=0\n",
    "    patience_limit=10\n",
    "    for epoch in tnrange(start_epoch, epochs):      \n",
    "        z_true_train = list()\n",
    "        z_pred_train = list()\n",
    "        total_loss_train = 0          \n",
    "        \n",
    "        t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n",
    "        for ((X,y),z) in t:\n",
    "            t.set_description(f'Epoch {epoch+1}')\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            pred = model(X, y)\n",
    "            \n",
    "            z = z.reshape(z.shape[0]*z.shape[1])\n",
    "            loss = loss_fn(pred, z)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item())\n",
    "            pred_idx = torch.max(pred, dim=1)[1]\n",
    "\n",
    "            \n",
    "            z_true_train += list(z.cpu().data.numpy())\n",
    "            z_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "        train_acc = accuracy_score(z_true_train, z_pred_train)\n",
    "        train_loss = total_loss_train/len(train_dl)\n",
    "        total_train_loss.append(train_loss)\n",
    "        total_train_acc.append(train_acc)\n",
    "        \n",
    "        if val_dl:\n",
    "            z_true_val = list()\n",
    "            z_pred_val = list()\n",
    "            total_loss_val = 0\n",
    "            for ((X,y),z) in tqdm_notebook(iter(val_dl), leave=False):\n",
    "                pred = model(X, y)\n",
    "                z = z.reshape(z.shape[0]*z.shape[1])\n",
    "                loss = loss_fn(pred, z)\n",
    "                pred_idx = torch.max(pred, 1)[1]\n",
    "                z_true_val += list(z.cpu().data.numpy())\n",
    "                z_pred_val += list(pred_idx.cpu().data.numpy())\n",
    "                total_loss_val += loss.item()\n",
    "                \n",
    "            valacc = accuracy_score(z_true_val, z_pred_val)\n",
    "            valloss = total_loss_val/len(val_dl)\n",
    "            print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {valloss:.4f} val_acc: {valacc:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f}')\n",
    "        total_val_loss.append(valloss)\n",
    "        total_val_acc.append(valacc)\n",
    "        \n",
    "        if valloss < prev_val_loss:\n",
    "            save_checkpoint(model, opt, \n",
    "                            total_train_loss,\n",
    "                            total_train_acc,\n",
    "                            total_val_loss,\n",
    "                            total_val_acc, \n",
    "                            lstm_model_file,\n",
    "                            epoch)\n",
    "            prev_val_loss = valloss\n",
    "            counter=0\n",
    "            print(\"This model saved!!!\")\n",
    "        else: \n",
    "            counter += 1\n",
    "            \n",
    "        if counter >= patience_limit: \n",
    "            print(\"Training stopped because maximum tolerance reached!!!\")\n",
    "            break\n",
    "            \n",
    "    return model, opt, total_train_loss, total_train_acc, total_val_loss, total_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, char_dim, batch_size, vocab_size, \n",
    "                 tagset_size, weights, one_hot_weight, bidirection=False, num_layers=1,\n",
    "                char_level=False, pos_level=False, graph_level=False):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.bidirectional = bidirection\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.char_embed_num = char_vocab_length\n",
    "        self.graph_embed_num = graph_vocab_length\n",
    "        self.char_dim = char_dim\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(weights)\n",
    "        self.one_hot_embeddings = nn.Embedding(n_values, n_values, _weight=one_hot_weight)\n",
    "        self.char_embeddings = nn.Embedding(self.char_embed_num, self.char_dim, padding_idx=0)\n",
    "        self.graph_embeddings = nn.Embedding(self.graph_embed_num, self.char_dim, padding_idx=0)\n",
    "        self.char_level=char_level\n",
    "        self.pos_level=pos_level\n",
    "        self.graph_level=graph_level\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.char_embeddings.weight)\n",
    "        nn.init.xavier_uniform_(self.graph_embeddings.weight)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, self.hidden_dim, \n",
    "                            bidirectional=self.bidirectional, \n",
    "                            num_layers=self.num_layers)         \n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, \n",
    "                            bidirectional=self.bidirectional, \n",
    "                            num_layers=self.num_layers)\n",
    "        if self.bidirectional:\n",
    "            self.hidden2tag = nn.Linear(self.hidden_dim * 2, tagset_size)\n",
    "        else:\n",
    "            self.hidden2tag = nn.Linear(self.hidden_dim * 2, tagset_size)      \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout_embed = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear1=nn.Linear(self.embedding_dim, self.hidden_dim)\n",
    "        self.linear2=nn.Linear(self.hidden_dim, tagset_size)\n",
    "        \n",
    "        #------------CNN\n",
    "        # Changed here for padding_idx error\n",
    "        self.conv_filter_sizes=[3,4,5]\n",
    "        self.conv_filter_nums=self.char_dim       # 30\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = self.conv_filter_nums, \n",
    "                                              kernel_size = (fs, self.char_dim)) \n",
    "                                    for fs in self.conv_filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(self.conv_filter_sizes) * self.conv_filter_nums, self.char_dim)\n",
    "\n",
    "    def init_hidden(self, tensor_size):\n",
    "        if self.bidirectional:\n",
    "            h0 = torch.zeros(2 * self.num_layers, tensor_size[1], self.hidden_dim)\n",
    "            c0 = torch.zeros(2 * self.num_layers, tensor_size[1], self.hidden_dim)         \n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, tensor_size[1], self.hidden_dim)\n",
    "            c0 = torch.zeros(self.num_layers, tensor_size[1], self.hidden_dim)         \n",
    "        if device:\n",
    "            h0 = h0.to(device)\n",
    "            c0 = c0.to(device)\n",
    "        return (h0, c0)\n",
    "    \n",
    "    def get_char_tensor(self, X):\n",
    "        words=[]\n",
    "        for i in range(0, len(X)):\n",
    "            character=[]\n",
    "            char_int=[]\n",
    "            chunk = []\n",
    "            bigger_chunk = []\n",
    "            # For character-level\n",
    "            if self.char_level:\n",
    "                character+=\"\".join(str(x) for x in tensortosent(X[i]))\n",
    "                char_int+=(char_field.vocab.stoi[c] for c in character)\n",
    "            # For grapheme-level\n",
    "            else:\n",
    "                character+=[str(x) for x in grapheme_clusters(tensortosent(X[i]))]\n",
    "                char_int+=(graph_field.vocab.stoi[c] for c in character)\n",
    "            words.append(char_int)\n",
    "\n",
    "        # Get the max length of the words in a sentence\n",
    "        length = max(map(len, words))\n",
    "\n",
    "        # Padding to match the max_length words whose size is less than max(filter_size)\n",
    "        if length < max(self.conv_filter_sizes):\n",
    "            length += max(self.conv_filter_sizes) - length\n",
    "\n",
    "        # Zero-padding the unequal sentences\n",
    "        X_char=np.array([xi+[0]*(length-len(xi)) for xi in words])\n",
    "        X_char=torch.from_numpy(X_char)\n",
    "        \n",
    "        return X_char    \n",
    "    \n",
    "    \n",
    "    # ---------------------------------------CHARACTER FORWARD\n",
    "    def _char_forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: 3D tensor, [bs, max_len]\n",
    "        Returns:\n",
    "            char_conv_outputs: 3D tensor, [bs, max_len, output_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        max_len = inputs.size(1)\n",
    "        inputs=inputs.to(device)\n",
    "        if self.char_level:\n",
    "            input_embed = self.char_embeddings(inputs.to(torch.int64))  # [bs, ml, feature_dim]\n",
    "        else:\n",
    "            input_embed=self.graph_embeddings(inputs.to(torch.int64))\n",
    "        \n",
    "        # Since convolution is 2-dimension, we need 4 dimension tensor\n",
    "        input_embed = input_embed.unsqueeze(1)         # [bs, 1, max_len, feature_dim]\n",
    "        \n",
    "        # conv\n",
    "        conved = [F.relu(conv(input_embed)).squeeze(3) for conv in self.convs]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        return self.fc(cat)\n",
    "    \n",
    "    \n",
    "    def forward(self, X, y):\n",
    "#         print(\"Shape of X\", X.shape)\n",
    "        if self.char_level or self.graph_level:\n",
    "            # Get the X_char for each item in a batch here\n",
    "            # And concatenate in the end\n",
    "            # or do it insied get_char_tensor(X)\n",
    "            X_char=self.get_char_tensor(X)\n",
    "#             print(\"Shape of X_char\", X_char.shape)\n",
    "            \n",
    "        X = self.word_embeddings(X)\n",
    "        X = self.dropout_embed(X)\n",
    "\n",
    "        # Do the convolution here\n",
    "        if (self.char_level or self.graph_level):\n",
    "            char_conv = self._char_forward(X_char)\n",
    "            char_conv = char_conv.unsqueeze(1)\n",
    "#             print(\"Shape of char_conv\", char_conv.shape)            \n",
    "            X=torch.cat((X,char_conv), dim=-1)\n",
    "        \n",
    "        # Concatenate POS-embedding here\n",
    "        if self.pos_level:\n",
    "            POS = self.one_hot_embeddings(y)\n",
    "            X=torch.cat((X,POS), dim=-1)\n",
    "            \n",
    "        self.hidden = self.init_hidden(list(X.size()))\n",
    "        '''\n",
    "        This dropout was after LSTM layer, need to run experiment\n",
    "        and check result what happens, if it is kept before LSTM\n",
    "        All other researcher, have generally kept it before LSTM\n",
    "        '''\n",
    "        X = self.dropout(X)          \n",
    "        self.lstm.flatten_parameters()\n",
    "#         print(\"Shape of X before lstm\", X.shape)            \n",
    "        X, _ = self.lstm(X, self.hidden)  \n",
    "#         print(\"Shape of X after lstm\", X.shape)            \n",
    "#         self.rnn.flatten_parameters()   \n",
    "#         X, _ = self.rnn(X, self.hidden[0]) \n",
    "\n",
    "        X = torch.tanh(X)\n",
    "        tag_space = self.hidden2tag(X.view(-1, X.shape[2]))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY CHAR or GRAPHEME USED!!!!!!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac19e2ec4ae940ab90565d22fbeaa13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2493), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.2608 train_acc: 0.9211 | val_loss: 0.2188 val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LSTMTagger. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model saved!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2493), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss: 0.1814 train_acc: 0.9415 | val_loss: 0.1862 val_acc: 0.9342\n",
      "This model saved!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2493), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss: 0.1569 train_acc: 0.9491 | val_loss: 0.1780 val_acc: 0.9412\n",
      "This model saved!!!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = len(txt_field.vocab)\n",
    "CHAR_DIM = 30\n",
    "pos_level=False\n",
    "char_level=True\n",
    "graph_level=False\n",
    "EMBEDDING_DIM = vec.dim\n",
    "\n",
    "if (pos_level and (char_level or graph_level)):\n",
    "    assert(char_level != graph_level),\"Only one variable can be True at a time\"\n",
    "    print(\"POS AND CHAR/GRAPHEME BOTH USED!!!!!!!!\")\n",
    "    EMBEDDING_DIM += n_values + CHAR_DIM\n",
    "elif (char_level or graph_level):\n",
    "    assert(char_level != graph_level),\"Only one variable can be True at a time\"\n",
    "    print(\"ONLY CHAR or GRAPHEME USED!!!!!!!!\")\n",
    "    EMBEDDING_DIM += CHAR_DIM\n",
    "elif pos_level:\n",
    "    print(\"ONLY POS USED!!!!!!!!\")\n",
    "    EMBEDDING_DIM += n_values\n",
    "else:\n",
    "    print(\"NORMAL EMBEDDING USED!!!!!!!!\")\n",
    "\n",
    "HIDDEN_DIM=100\n",
    "tagset_size = len(label_field.vocab)\n",
    "batch_size=1\n",
    "weights = txt_field.vocab.vectors\n",
    "\n",
    "lstm_model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, CHAR_DIM, batch_size=batch_size,\n",
    "                        vocab_size=vocab_size, tagset_size=tagset_size,\n",
    "                        weights=weights,one_hot_weight=one_hot_weight,\n",
    "                        bidirection=True, num_layers=1, char_level=char_level,\n",
    "                       pos_level=pos_level, graph_level=graph_level).to(device)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "opt = optim.Adam(filter(lambda p: p.requires_grad, lstm_model.parameters()), lr=0.001, weight_decay=0.000001)\n",
    "\n",
    "num_of_epochs=3\n",
    "\n",
    "train_iter, val_iter = data.BucketIterator.splits(datasets=(train_ds, val_ds), \n",
    "                                            batch_sizes=(batch_size, batch_size), \n",
    "                                            sort_key=lambda x: len(x.TEXT), \n",
    "                                            device=device, \n",
    "                                            sort_within_batch=True, \n",
    "                                            repeat=False,\n",
    "                                            shuffle=True)\n",
    "\n",
    "train_batch_it = BatchGenerator(train_iter, 'TEXT', 'POS', 'TAG')\n",
    "val_batch_it = BatchGenerator(val_iter, 'TEXT', 'POS', 'TAG')\n",
    "\n",
    "model_name='lstm'\n",
    "\n",
    "lstm_model_file = './data/models/' + model_name + '.pth'\n",
    "\n",
    "if os.path.exists(lstm_model_file):\n",
    "    os.remove(lstm_model_file)\n",
    "\n",
    "if os.path.exists(lstm_model_file):\n",
    "    lstm_model, opt, lstm_train_loss, lstm_train_acc, lstm_val_loss, lstm_val_acc, epoch = load_checkpoint(lstm_model_file)\n",
    "\n",
    "    print(f'Epoch {epoch}: train_loss: {lstm_train_loss[-1]:.4f} train_acc: {lstm_train_acc[-1]:.4f} | val_loss: {lstm_val_loss[-1]:.4f} val_acc: {lstm_val_acc[-1]:.4f}')\n",
    "    # Resume training (Need to fix it)\n",
    "    if num_of_epochs > epoch:\n",
    "        lstm_model, opt, tmp_train_loss, tmp_train_acc, tmp_val_loss, tmp_val_acc = fit(model=lstm_model,\n",
    "                                                                                       train_dl=train_batch_it, \n",
    "                                                                                       val_dl=val_batch_it, \n",
    "                                                                                       loss_fn=loss_func, \n",
    "                                                                                       opt=opt,\n",
    "                                                                                       start_epoch=epoch,\n",
    "                                                                                       epochs=num_of_epochs)\n",
    "        lstm_train_loss += tmp_train_loss\n",
    "        lstm_train_acc += tmp_train_acc\n",
    "        lstm_val_loss += tmp_val_loss\n",
    "        lstm_val_acc += tmp_val_acc\n",
    "        \n",
    "        save_checkpoint(lstm_model, opt, \n",
    "                        lstm_train_loss,\n",
    "                        lstm_train_acc,\n",
    "                        lstm_val_loss,\n",
    "                        lstm_val_acc,\n",
    "                        lstm_model_file, \n",
    "                        num_of_epochs)\n",
    "\n",
    "else:\n",
    "    lstm_model, opt, lstm_train_loss, lstm_train_acc, lstm_val_loss, lstm_val_acc = fit(model=lstm_model,\n",
    "                                                                                        train_dl=train_batch_it,\n",
    "                                                                                        val_dl=val_batch_it,\n",
    "                                                                                        loss_fn=loss_func,\n",
    "                                                                                        opt=opt,\n",
    "                                                                                        start_epoch=0,\n",
    "                                                                                        lstm_model_file=lstm_model_file,\n",
    "                                                                                        epochs=num_of_epochs)\n",
    "    save_checkpoint(lstm_model, opt, \n",
    "                lstm_train_loss,\n",
    "                lstm_train_acc,\n",
    "                lstm_val_loss,\n",
    "                lstm_val_acc,\n",
    "                lstm_model_file, \n",
    "                num_of_epochs)\n",
    "\n",
    "plot_loss(lstm_train_loss, lstm_val_loss, title='LSTM Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model!!!\n",
      "Writing in file:  ./data/ner/results/lstm_train.txt\n",
      "Writing in file:  ./data/ner/results/lstm_test.txt\n",
      "Writing in file:  ./data/ner/results/lstm_val.txt\n"
     ]
    }
   ],
   "source": [
    "def write_results(model, dataset, train_file, test_file, val_file):\n",
    "\n",
    "    train_iter, test_iter, val_iter = data.BucketIterator.splits(datasets=dataset, \n",
    "                                                batch_sizes=(1, 1, 1), \n",
    "                                                sort_key=lambda x: len(x.TEXT), \n",
    "                                                device=device, \n",
    "                                                sort_within_batch=True, \n",
    "                                                repeat=False,\n",
    "                                                shuffle=False)\n",
    "\n",
    "    train_batch_it = BatchGenerator(train_iter, 'TEXT', 'POS', 'TAG')\n",
    "    test_batch_it = BatchGenerator(test_iter, 'TEXT', 'POS', 'TAG')\n",
    "    val_batch_it = BatchGenerator(val_iter, 'TEXT', 'POS', 'TAG')\n",
    "\n",
    "    with open(train_file, 'w', encoding='utf-8') as rtrn:\n",
    "        model.eval()\n",
    "        print('Writing in file: ',train_file)\n",
    "        for ((X,y),z) in iter(train_batch_it):\n",
    "            sent = NumpyToSent(X)\n",
    "            pred = model(X,y)\n",
    "            pred_idx = torch.max(pred, 1)[1]\n",
    "\n",
    "            z = z.view(-1)\n",
    "            z_true_val = z.cpu().data.numpy().tolist()\n",
    "            true_tag = PredToTag(z_true_val)\n",
    "\n",
    "            z_pred_val = pred_idx.cpu().data.numpy().tolist()\n",
    "            pred_tag = PredToTag(z_pred_val)\n",
    "\n",
    "            for s, gt, pt in zip(sent, true_tag, pred_tag):\n",
    "                rtrn.write(s+' '+gt+' '+pt+'\\n')\n",
    "            rtrn.write('\\n')\n",
    "    rtrn.close()\n",
    "    \n",
    "    with open(test_file, 'w', encoding='utf-8') as rtst:\n",
    "        model.eval()\n",
    "        print('Writing in file: ',test_file)\n",
    "        for ((X,y),z) in iter(test_batch_it):\n",
    "            sent = NumpyToSent(X)\n",
    "            pred = model(X,y)\n",
    "            pred_idx = torch.max(pred, 1)[1]\n",
    "\n",
    "            z = z.view(-1)\n",
    "            z_true_val = z.cpu().data.numpy().tolist()\n",
    "            true_tag = PredToTag(z_true_val)\n",
    "\n",
    "            z_pred_val = pred_idx.cpu().data.numpy().tolist()\n",
    "            pred_tag = PredToTag(z_pred_val)\n",
    "\n",
    "            for s, gt, pt in zip(sent, true_tag, pred_tag):\n",
    "                rtst.write(s+' '+gt+' '+pt+'\\n')\n",
    "            rtst.write('\\n')\n",
    "    rtst.close()\n",
    "    \n",
    "    with open(val_file, 'w', encoding='utf-8') as rval:\n",
    "        model.eval()\n",
    "        print('Writing in file: ',val_file)\n",
    "        for ((X,y),z) in iter(val_batch_it):\n",
    "            sent = NumpyToSent(X)\n",
    "            pred = model(X,y)\n",
    "            pred_idx = torch.max(pred, 1)[1]\n",
    "\n",
    "            z = z.view(-1)\n",
    "            z_true_val = z.cpu().data.numpy().tolist()\n",
    "            true_tag = PredToTag(z_true_val)\n",
    "\n",
    "            z_pred_val = pred_idx.cpu().data.numpy().tolist()\n",
    "            pred_tag = PredToTag(z_pred_val)\n",
    "\n",
    "            for s, gt, pt in zip(sent, true_tag, pred_tag):\n",
    "                rval.write(s+' '+gt+' '+pt+'\\n')\n",
    "            rval.write('\\n')\n",
    "    rval.close()    \n",
    "\n",
    "file_train=model_name +'_train.txt'\n",
    "file_test=model_name +'_test.txt'\n",
    "file_val=model_name +'_val.txt'\n",
    "\n",
    "result_train = './data/ner/results/' + file_train\n",
    "result_test = './data/ner/results/' + file_test\n",
    "result_val = './data/ner/results/' + file_val\n",
    "\n",
    "load_best_model=True\n",
    "if load_best_model:\n",
    "    print(\"Loading best model!!!\")\n",
    "    lstm_model, opt, lstm_train_loss, lstm_train_acc, lstm_val_loss, lstm_val_acc, epoch = load_checkpoint(lstm_model_file)\n",
    "\n",
    "write_results(model=lstm_model, dataset=(train_ds, test_ds, val_ds), \n",
    "              train_file=result_train,\n",
    "              test_file=result_test, \n",
    "              val_file=result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f70dcca6bfe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result_train' is not defined"
     ]
    }
   ],
   "source": [
    "result_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-96ee6488105f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mYou\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mseparately\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_conll_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./logs/conll_log1.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result_train' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    These are NOT actual CONLL evaluation\n",
    "    You need to run separately\n",
    "\"\"\"\n",
    "e.evaluate_conll_file('./logs/conll_log1.txt', result_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.evaluate_conll_file(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.evaluate_conll_file(result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed everything"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('Completed everything')\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_truth_pred(fileName):\n",
    "    true_seqs, pred_seqs = [], []\n",
    "    \n",
    "    with open(fileName, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            cols = line.strip().split()\n",
    "            # each non-empty line must contain >= 3 columns\n",
    "            if not cols:\n",
    "                true_seqs.append('O')\n",
    "                pred_seqs.append('O')\n",
    "            elif len(cols) < 3:\n",
    "                raise IOError(\"conlleval: too few columns in line %s\\n\" % line)\n",
    "            else:\n",
    "                # extract tags from last 2 columns\n",
    "                true_seqs.append(cols[-2])\n",
    "                pred_seqs.append(cols[-1])\n",
    "    return true_seqs, pred_seqs\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def display_confusion_matrix(filename, title):\n",
    "    y_true, y_pred = get_truth_pred(filename)\n",
    "    labels=[\"B-PER\", \"B-LOC\", \"B-ORG\", \"B-MISC\", \"I-PER\", \"I-LOC\", \"I-ORG\", \"I-MISC\", \"O\", \"<pad>\"]\n",
    "    labels=[\"PER\", \"LOC\", \"ORG\", \"MISC\", \"O\", \"<pad>\"]\n",
    "    \n",
    "#     tag_dict = {\"B-PER\": 0, \"B-LOC\": 1, \"B-ORG\": 2, \"B-MISC\" : 3, \"I-PER\": 4, \"I-LOC\": 5, \"I-ORG\": 6, \"I-MISC\":7, \"O\": 8, '<pad>':9}\n",
    "    tag_dict = {\"PER\": 0, \"LOC\": 1, \"ORG\": 2, \"MISC\" : 3, \"O\": 4, '<pad>':5}\n",
    "\n",
    "    y_true_final = list(map(tag_dict.get, y_true))\n",
    "    y_pred_final = list(map(tag_dict.get, y_pred))\n",
    "\n",
    "    plot_confusion_matrix(y_true_final, y_pred_final, classes=labels, normalize=False, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(result_train, 'Confusion matrix on train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(result_test, 'Confusion matrix on test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(result_val, 'Confusion matrix on val data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "'''\n",
    "    Get the TP/FP/FN based on PER/ORG/LOC TAG only\n",
    "'''\n",
    "def get_stats(src_file, dest_file):\n",
    "    df = pd.read_csv(src_file, delimiter=' ', encoding='utf-8', skip_blank_lines=True, quoting=csv.QUOTE_NONE, header=None, names=['TEXT', 'GT', 'PT'])\n",
    "    entity_df = df[(df.PT == 'ORG') | (df.PT == 'PER') | (df.PT == 'LOC') | (df.GT == 'ORG') | (df.GT == 'PER') | (df.GT == 'LOC') | (df.GT == 'MISC') | (df.PT == 'MISC')].reset_index(drop=True)\n",
    "    \n",
    "    num_of_words = len(entity_df)\n",
    "\n",
    "    acc_df = entity_df[entity_df.GT == entity_df.PT].reset_index(drop=True)\n",
    "\n",
    "    org_tp = acc_df[acc_df.GT == 'ORG'].reset_index(drop=True)\n",
    "    org_tp['COMMENTS']='ORG_TP'\n",
    "    per_tp = acc_df[acc_df.GT == 'PER'].reset_index(drop=True)\n",
    "    per_tp['COMMENTS']='PER_TP'\n",
    "    loc_tp = acc_df[acc_df.GT == 'LOC'].reset_index(drop=True)\n",
    "    loc_tp['COMMENTS']='LOC_TP'\n",
    "    misc_tp = acc_df[acc_df.GT == 'MISC'].reset_index(drop=True)\n",
    "    misc_tp['COMMENTS']='MISC_TP'\n",
    "\n",
    "    org_fn = entity_df[(entity_df.GT == 'ORG') & (entity_df.PT != 'ORG')].reset_index(drop=True)\n",
    "    org_fn['COMMENTS']='ORG_FN'\n",
    "    per_fn = entity_df[(entity_df.GT == 'PER') & (entity_df.PT != 'PER')].reset_index(drop=True)\n",
    "    per_fn['COMMENTS']='PER_FN'\n",
    "    loc_fn = entity_df[(entity_df.GT == 'LOC') & (entity_df.PT != 'LOC')].reset_index(drop=True)\n",
    "    loc_fn['COMMENTS']='LOC_FN'\n",
    "    misc_fn = entity_df[(entity_df.GT == 'MISC') & (entity_df.PT != 'MISC')].reset_index(drop=True)\n",
    "    misc_fn['COMMENTS']='MISC_FN'    \n",
    "\n",
    "    org_fp = entity_df[(entity_df.PT == 'ORG') & (entity_df.GT != 'ORG')].reset_index(drop=True)\n",
    "    org_fp['COMMENTS']='ORG_FP'\n",
    "    per_fp = entity_df[(entity_df.PT == 'PER') & (entity_df.GT != 'PER')].reset_index(drop=True)\n",
    "    per_fp['COMMENTS']='PER_FP'\n",
    "    loc_fp = entity_df[(entity_df.PT == 'LOC') & (entity_df.GT != 'LOC')].reset_index(drop=True)\n",
    "    loc_fp['COMMENTS']='LOC_FP'\n",
    "    misc_fp = entity_df[(entity_df.PT == 'MISC') & (entity_df.GT != 'MISC')].reset_index(drop=True)\n",
    "    misc_fp['COMMENTS']='MISC_FP'    \n",
    "    \n",
    "    final_df=pd.concat([org_tp, per_tp, loc_tp, misc_tp, org_fn, per_fn, loc_fn, misc_fn, org_fp, per_fp, loc_fp, misc_fp], ignore_index=True)\n",
    "    final_df.to_csv(dest_file, sep='\\t',encoding='utf-8',index=False,header=True)\n",
    "    return final_df\n",
    "\n",
    "file=file_train\n",
    "root='../data/ner/results/'\n",
    "source_file = root+file\n",
    "dest_file=root+'stat_'+file\n",
    "result_df=get_stats(source_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[(result_df.COMMENTS=='LOC_FN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df=result_df[result_df.COMMENTS=='ORG_FN']\n",
    "\n",
    "list_text=list(count_df.TEXT.values)\n",
    "\n",
    "import collections\n",
    "counter=collections.Counter(list_text)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
